{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Generation for GISCUP 2023\n",
    "\n",
    "The following model created is based on the excellent research produced by Dumitru et al. in their paper 'Using DUCK-Net for polyp image segmentation'. Most of the following code has been directly copied from their open-source project found at the following URL: https://github.com/RazvanDu/DUCK-Net.\n",
    "\n",
    "We used the DUCK-Net architecture but reduced the number of filters from 17 to 4. We found through the use of hyperparameter tuning (using Hyperband) that 4 filters gave the best results. We also trained this model using various generated datasets which included DEM, Hillshade and other raster data. We found that the best results were produced by using just RGB data.\n",
    "\n",
    "Note: When running the following, it is assumed that the dataset produced by running the make_training_dataset notebook is available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, add\n",
    "from keras.layers import Conv2D\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, UpSampling2D\n",
    "from keras.layers import add\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_initializer = 'he_uniform'\n",
    "\n",
    "def conv_block_2D(x, filters, block_type, repeat=1, dilation_rate=1, size=3, padding='same'):\n",
    "    result = x\n",
    "\n",
    "    for i in range(0, repeat):\n",
    "\n",
    "        if block_type == 'separated':\n",
    "            result = separated_conv2D_block(result, filters, size=size, padding=padding)\n",
    "        elif block_type == 'duckv2':\n",
    "            result = duckv2_conv2D_block(result, filters, size=size)\n",
    "        elif block_type == 'midscope':\n",
    "            result = midscope_conv2D_block(result, filters)\n",
    "        elif block_type == 'widescope':\n",
    "            result = widescope_conv2D_block(result, filters)\n",
    "        elif block_type == 'resnet':\n",
    "            result = resnet_conv2D_block(result, filters, dilation_rate)\n",
    "        elif block_type == 'conv':\n",
    "            result = Conv2D(filters, (size, size),\n",
    "                            activation='relu', kernel_initializer=kernel_initializer, padding=padding)(result)\n",
    "        elif block_type == 'double_convolution':\n",
    "            result = double_convolution_with_batch_normalization(result, filters, dilation_rate)\n",
    "\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def duckv2_conv2D_block(x, filters, size):\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x1 = widescope_conv2D_block(x, filters)\n",
    "\n",
    "    x2 = midscope_conv2D_block(x, filters)\n",
    "\n",
    "    x3 = conv_block_2D(x, filters, 'resnet', repeat=1)\n",
    "\n",
    "    x4 = conv_block_2D(x, filters, 'resnet', repeat=2)\n",
    "\n",
    "    x5 = conv_block_2D(x, filters, 'resnet', repeat=3)\n",
    "\n",
    "    x6 = separated_conv2D_block(x, filters, size=6, padding='same')\n",
    "\n",
    "    x = add([x1, x2, x3, x4, x5, x6])\n",
    "\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def separated_conv2D_block(x, filters, size=3, padding='same'):\n",
    "    x = Conv2D(filters, (1, size), activation='relu', kernel_initializer=kernel_initializer, padding=padding)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = Conv2D(filters, (size, 1), activation='relu', kernel_initializer=kernel_initializer, padding=padding)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def midscope_conv2D_block(x, filters):\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n",
    "               dilation_rate=1)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n",
    "               dilation_rate=2)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def widescope_conv2D_block(x, filters):\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n",
    "               dilation_rate=1)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n",
    "               dilation_rate=2)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n",
    "               dilation_rate=3)(x)\n",
    "\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_conv2D_block(x, filters, dilation_rate=1):\n",
    "    x1 = Conv2D(filters, (1, 1), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n",
    "                dilation_rate=dilation_rate)(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n",
    "               dilation_rate=dilation_rate)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n",
    "               dilation_rate=dilation_rate)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x_final = add([x, x1])\n",
    "\n",
    "    x_final = BatchNormalization(axis=-1)(x_final)\n",
    "\n",
    "    return x_final\n",
    "\n",
    "\n",
    "def double_convolution_with_batch_normalization(x, filters, dilation_rate=1):\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n",
    "               dilation_rate=dilation_rate)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "    x = Conv2D(filters, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same',\n",
    "               dilation_rate=dilation_rate)(x)\n",
    "    x = BatchNormalization(axis=-1)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "kernel_initializer = 'he_uniform'\n",
    "interpolation = \"nearest\"\n",
    "\n",
    "def create_model(img_height, img_width, input_chanels, out_classes, starting_filters):\n",
    "    input_layer = tf.keras.layers.Input((img_height, img_width, input_chanels))\n",
    "\n",
    "    print('Starting DUCK-Net')\n",
    "\n",
    "    p1 = Conv2D(starting_filters * 2, 2, strides=2, padding='same')(input_layer)\n",
    "    p2 = Conv2D(starting_filters * 4, 2, strides=2, padding='same')(p1)\n",
    "    p3 = Conv2D(starting_filters * 8, 2, strides=2, padding='same')(p2)\n",
    "    p4 = Conv2D(starting_filters * 16, 2, strides=2, padding='same')(p3)\n",
    "    p5 = Conv2D(starting_filters * 32, 2, strides=2, padding='same')(p4)\n",
    "\n",
    "    t0 = conv_block_2D(input_layer, starting_filters, 'duckv2', repeat=1)\n",
    "\n",
    "    l1i = Conv2D(starting_filters * 2, 2, strides=2, padding='same')(t0)\n",
    "    s1 = add([l1i, p1])\n",
    "    t1 = conv_block_2D(s1, starting_filters * 2, 'duckv2', repeat=1)\n",
    "\n",
    "    l2i = Conv2D(starting_filters * 4, 2, strides=2, padding='same')(t1)\n",
    "    s2 = add([l2i, p2])\n",
    "    t2 = conv_block_2D(s2, starting_filters * 4, 'duckv2', repeat=1)\n",
    "\n",
    "    l3i = Conv2D(starting_filters * 8, 2, strides=2, padding='same')(t2)\n",
    "    s3 = add([l3i, p3])\n",
    "    t3 = conv_block_2D(s3, starting_filters * 8, 'duckv2', repeat=1)\n",
    "\n",
    "    l4i = Conv2D(starting_filters * 16, 2, strides=2, padding='same')(t3)\n",
    "    s4 = add([l4i, p4])\n",
    "    t4 = conv_block_2D(s4, starting_filters * 16, 'duckv2', repeat=1)\n",
    "\n",
    "    l5i = Conv2D(starting_filters * 32, 2, strides=2, padding='same')(t4)\n",
    "    s5 = add([l5i, p5])\n",
    "    t51 = conv_block_2D(s5, starting_filters * 32, 'resnet', repeat=2)\n",
    "    t53 = conv_block_2D(t51, starting_filters * 16, 'resnet', repeat=2)\n",
    "\n",
    "    l5o = UpSampling2D((2, 2), interpolation=interpolation)(t53)\n",
    "    c4 = add([l5o, t4])\n",
    "    q4 = conv_block_2D(c4, starting_filters * 8, 'duckv2', repeat=1)\n",
    "\n",
    "    l4o = UpSampling2D((2, 2), interpolation=interpolation)(q4)\n",
    "    c3 = add([l4o, t3])\n",
    "    q3 = conv_block_2D(c3, starting_filters * 4, 'duckv2', repeat=1)\n",
    "\n",
    "    l3o = UpSampling2D((2, 2), interpolation=interpolation)(q3)\n",
    "    c2 = add([l3o, t2])\n",
    "    q6 = conv_block_2D(c2, starting_filters * 2, 'duckv2', repeat=1)\n",
    "\n",
    "    l2o = UpSampling2D((2, 2), interpolation=interpolation)(q6)\n",
    "    c1 = add([l2o, t1])\n",
    "    q1 = conv_block_2D(c1, starting_filters, 'duckv2', repeat=1)\n",
    "\n",
    "    l1o = UpSampling2D((2, 2), interpolation=interpolation)(q1)\n",
    "    c0 = add([l1o, t0])\n",
    "    z1 = conv_block_2D(c0, starting_filters, 'duckv2', repeat=1)\n",
    "\n",
    "    output = Conv2D(out_classes, (1, 1), activation='sigmoid')(z1)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "    return model\n",
    "\n",
    "def dice_metric_loss(ground_truth, predictions, smooth=1e-6):\n",
    "    ground_truth = K.cast(ground_truth, tf.float32)\n",
    "    predictions = K.cast(predictions, tf.float32)\n",
    "    ground_truth = K.flatten(ground_truth)\n",
    "    predictions = K.flatten(predictions)\n",
    "    intersection = K.sum(predictions * ground_truth)\n",
    "    union = K.sum(predictions) + K.sum(ground_truth)\n",
    "\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "    return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is already scaled when generating the dataset\n",
    "TRAINING_DATA = Path(\"../data/training_data/RGB256/\")\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "data = tf.data.Dataset.load(str(TRAINING_DATA)).shuffle(BUFFER_SIZE, 42, reshuffle_each_iteration=False)\n",
    "\n",
    "total = len(data)\n",
    "train_size = int(total*0.8)\n",
    "train_ds = data.take(train_size)\n",
    "val_ds = data.skip(train_size)\n",
    "\n",
    "class Augment(tf.keras.layers.Layer):\n",
    "  def __init__(self, seed=42):\n",
    "    super().__init__()\n",
    "    # both use the same seed, so they'll make the same random changes.\n",
    "    self.flip_x = tf.keras.layers.RandomFlip(seed=seed)\n",
    "\n",
    "    self.flip_y = tf.keras.layers.RandomFlip(seed=seed)\n",
    "\n",
    "  def call(self, inputs, labels):\n",
    "    inputs = self.flip_x(inputs)\n",
    "\n",
    "    labels = self.flip_y(labels)\n",
    "    return inputs, labels\n",
    "\n",
    "train_ds = train_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).map(Augment()).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 256\n",
    "learning_rate = 1e-4\n",
    "filters = 4\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "model = create_model(img_height=img_size, img_width=img_size, input_chanels=3, out_classes=1, starting_filters=filters)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=dice_metric_loss,\n",
    "              metrics=[tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "model.fit(train_ds, epochs=100, validation_data=val_ds, callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../model/RGB_256_filters_4\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "giscup3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
